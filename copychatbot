import os
import fitz  # PyMuPDF
from flask import Flask, request, jsonify, session
from sentence_transformers import SentenceTransformer, util
from transformers import GPT2Tokenizer, GPT2LMHeadModel

app = Flask(__name__)
app.secret_key = 'your_secret_key'

PDF_FOLDER = "/home/dans/workspace/smc_llms/in/pdfs"

# Load models once
sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')

def extract_text_with_metadata(pdf_path):
    doc = fitz.open(pdf_path)
    pdf_text = {}
    metadata = {
        "product_name": "Unknown",
        "version": "Unknown",
        "categories": []
    }
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text = page.get_text()
        pdf_text[page_num + 1] = text
        # Extract metadata from the first page
        if page_num == 0:
            metadata["product_name"] = extract_product_name(text)
            metadata["version"] = extract_version(text)
            metadata["categories"] = extract_categories(text)
    return pdf_text, metadata

def extract_product_name(text):
    # Implement logic to extract product name from text
    if "Product Name:" in text:
        return text.split("Product Name:")[1].split('\n')[0].strip()
    return "Sample Product"

def extract_version(text):
    # Implement logic to extract version from text
    if "Version:" in text:
        return text.split("Version:")[1].split('\n')[0].strip()
    return "1.0"

def extract_categories(text):
    # Implement logic to extract categories from text
    if "Categories:" in text:
        return [category.strip() for category in text.split("Categories:")[1].split('\n')[0].split(',')]
    return ["Category1", "Category2"]

def create_embeddings(model, pdf_text):
    embeddings = {}
    for page_num, text in pdf_text.items():
        sentences = text.split('\n')
        embeddings[page_num] = model.encode(sentences, convert_to_tensor=True)
    return embeddings

pdf_data = {}

def load_pdfs():
    global pdf_data
    for pdf_file in os.listdir(PDF_FOLDER):
        if pdf_file.endswith(".pdf"):
            pdf_path = os.path.join(PDF_FOLDER, pdf_file)
            pdf_text, metadata = extract_text_with_metadata(pdf_path)
            pdf_embeddings = create_embeddings(sentence_model, pdf_text)
            pdf_data[pdf_file] = (pdf_text, pdf_embeddings, metadata)

def search_answer_in_pdfs(question):
    question_embedding = sentence_model.encode(question, convert_to_tensor=True)
    best_score = -1
    best_result = None

    for pdf_name, (pdf_text, pdf_embeddings, metadata) in pdf_data.items():
        for page_num, embeddings in pdf_embeddings.items():
            scores = util.pytorch_cos_sim(question_embedding, embeddings)
            max_score, max_idx = scores.max(dim=1)
            if max_score.item() > best_score:
                best_score = max_score.item()
                best_result = {
                    "pdf": pdf_name,
                    "page": page_num,
                    "sentence": pdf_text[page_num].split('\n')[max_idx.item()],
                    "metadata": metadata
                }

    if best_result and best_score > 0.5:
        return {
            "pdf": best_result['pdf'],
            "page": best_result['page'],
            "sentence": best_result['sentence'],
            "metadata": best_result['metadata']
        }
    return "No relevant answer found in the PDFs."
    
@app.route('/chat', methods=['POST'])
def ask():
    question = request.json.get('question')
    conversation_history = session.get('conversation_history', [])
    conversation_history.append(f"User: {question}")

    search_result = search_answer_in_pdfs(question)
    if isinstance(search_result, dict):
        retrieved_text = f"Answer found in {search_result['pdf']} (Page {search_result['page']}): {search_result['sentence']} (Metadata: {search_result['metadata']})"
    else:
        retrieved_text = search_result

    generated_answer = generate_answer(question, retrieved_text)
    
    conversation_history.append(f"Bot: {generated_answer}")
    session['conversation_history'] = conversation_history

    return jsonify({"question": question, "answer": generated_answer, "conversation_history": conversation_history})

def generate_answer(question, context):
    input_text = f"Question: {question}\nContext: {context}\nAnswer:"
    inputs = gpt2_tokenizer.encode(input_text, return_tensors='pt')
    outputs = gpt2_model.generate(inputs, max_length=150, num_return_sequences=1)
    answer = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)
    return answer.split("Answer:")[-1].strip()

@app.route('/')
def home():
    with open("templates/chat.html", "rt") as file:
        return file.read()

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=5000, debug=True)